{
    "componentChunkName": "component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-post-query-tsx",
    "path": "/conformer-convolution-augmented-transformer-for-speech-recognition",
    "result": {"data":{"post":{"slug":"/conformer-convolution-augmented-transformer-for-speech-recognition","title":"[Paper-review] Conformer: Convolution-augmented Transformer for Speech Recognition","date":"22.03.2022","tags":[{"name":"Papers","slug":"papers"},{"name":"NLP","slug":"nlp"},{"name":"ASR","slug":"asr"}],"description":null,"canonicalUrl":null,"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"slug\": \"conformer-convolution-augmented-transformer-for-speech-recognition\",\n  \"title\": \"[Paper-review] Conformer: Convolution-augmented Transformer for Speech Recognition\",\n  \"date\": \"2022-03-22T00:00:00.000Z\",\n  \"tags\": [\"Papers\", \"NLP\", \"ASR\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"In this papers, authors introduced Conformer, an architecture that \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"integrate components from CNN and Transformer\"), \" for end-to-end speech recognition. The importance of each component have been studied and they show that \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"the inclusion of CNN is critical to the performance of Conformer model.\"), \" Conformer achieved better accuracy with fewer parameters than previous network.\"), mdx(\"h2\", null, mdx(\"em\", {\n    parentName: \"h2\"\n  }, \"Problem:\")), mdx(\"p\", null, \"Recently, the Transformer architecture based on self-attention has been very popular due to their efficiency. CNN have also been successful for ASR, which capture local context progressively via local receptive layer by layer. However, they have some limitations. While Transformers are good at modeling long-range global context, they are less capable to extract fine-grained local feature patterns. CNNs on another hand,  which is good at exploiting local information but need many more layers or parameters to capture global information.\"), mdx(\"h2\", null, mdx(\"em\", {\n    parentName: \"h2\"\n  }, \"Proposed Method:\")), mdx(\"p\", null, \"Author proposed a novel combination of CNN with self-attention in ASR models. The new  combination can achieve the best of worlds - self-attention for global information and CNN\"), mdx(\"h2\", null, \"Conformer Encoder\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"960px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"107.08333333333333%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC9ElEQVQ4y4WVaW/bRhCG/f9/S4HCBdoPjtOiQRTHkOpLlVRbIiVGB0VKFG/uLq+n2HWouIUtDzBYcnb25TvHDs8AiqLgEASoskQoRV4U1E1DVVVIKUmSBN/3WS6XbLdb4jhGCEFd1/o4bdvSyVn30gChbXP4a0Aw6JM4C7KiMIBKKZI0Yb1xiaLI2PTHtL4O2LbPgI//4H78yPrykmAyIReCsiyPzs4mpiprqrJ6n6HezLKEONoTBj5SFGRZRhRGZCrF3lpM1zO2iUuYHZBCvg3YGbx8y9XsiivrK27q0jYtnuezDBw+j/7ky/gTn4Z/sPDnlKqkql8J2eSvqUnihCDdY3szpptHEhkbh5chf/MS4rQgL4TJ46sMnw0NZdVA5CCtHsLqQbJEu0mpaMoIlS7Z+3NE7KCKACFOATYNUpU0mYtyHxCbeyg8A6hURZnY7Ocf8K0LdvYFRThFyJL67ZAbsjwj3CWsLI9vU5csEsZBM+nECzNUVZp+fTPkl0XZryJ+P+9xed7DcwJjk0qhoohsuWL1OCewLFLfR5zOYUsUx2RawwPxzqdS0vSnqmvC8Qj7l3PGP//E8rdfCScTZFlRn2xsvRRzouWFUcTie1EkrZQ0Scx2viDduuRR+B7DhjhJkZlPEVlkwRNU8TOgED/aZptS1S3lqZvSGfS9NCy/3+vOrhs4yPaMnCFj529sf8Yu8U07nQTsVs2200b3pypZH1b0p9d8HX+hN/qM4y9QUhkSXVE7jLOX6K+JbqmmfubcTZluAv1fNJZhqGed67qkacpqtWI6nbLZbMzsWywWZg7OZjOz2rZtVJ/Ro2y9XuN53nGUGUDHcbi+vjaOw+HQ6Gg04uHhgdvbW+7v7+n3++ZZ683NjfHR/nd3d0bzPP8v4GQyOYJYlmWcuufBYMB4PDbAmqkG64B0NNquozsC6rD04aenJxPybrczoWjVoen9MAxNCvb7/fFXoNMUBIFZu5waQP3P0BuHw4H3inRKdFH+BQlCRe0Ht7vGAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"29E70EA1 F513 4F57 8CC3 62CB5FA7BE38\",\n    \"title\": \"29E70EA1 F513 4F57 8CC3 62CB5FA7BE38\",\n    \"src\": \"/static/a714cfda2fde0518fae5681cdde7cbc2/7d769/29E70EA1-F513-4F57-8CC3-62CB5FA7BE38.png\",\n    \"srcSet\": [\"/static/a714cfda2fde0518fae5681cdde7cbc2/5243c/29E70EA1-F513-4F57-8CC3-62CB5FA7BE38.png 240w\", \"/static/a714cfda2fde0518fae5681cdde7cbc2/ab158/29E70EA1-F513-4F57-8CC3-62CB5FA7BE38.png 480w\", \"/static/a714cfda2fde0518fae5681cdde7cbc2/7d769/29E70EA1-F513-4F57-8CC3-62CB5FA7BE38.png 960w\", \"/static/a714cfda2fde0518fae5681cdde7cbc2/4553e/29E70EA1-F513-4F57-8CC3-62CB5FA7BE38.png 1098w\"],\n    \"sizes\": \"(max-width: 960px) 100vw, 960px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(\"p\", null, \"As shown in Figure 1, Conformer block composed of \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"4 modules\"), \" stacked together (i.e: feed-forward + multi-head-self-attention + convolution + feed-forward)\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Multi-Headed Self-Attention Module:\"), \" utilize the relative positional embedding from Transformer-XL, which help generalize better on different input length. A residual units with dropout helps training and regularizing deeper models. \"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"960px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"42.91666666666667%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABiElEQVQoz52SW2/aQBBG/f//RtTXKorSlyhFRQ0VbsCk4mKKsLk4MdhejO82DuZUuySReKnUjnS0O/N9O1rtrHY6nWgaOL7RKE6A5DKkV5Wbs3xq5NnmQ5NoVVWRxR5VtqUufMrUpcxDdv6ewBWIbajwXUGSJASxj0gD/NgjSvdkWXbRVIuiiGr3SPJ8z8v0lmL7lToa89j+xfXVLdefvvD56oZvNz+wrAVPrsH94I6H2XfmwYzfC4+8fFVXVg1V68qhjk3qeAblHF59st2Bpekw7JmYTzN2zwlZmvGSOiyFjS0sRB5QHZqLJ9Fcd0MQCPKiZL12sCyb1WrNfD7H8zw2m41isVwQBIHar5YrkjhBCEGR54RhqLyqYa/XwzD6OI5Dt9tF73b5qev0+310XUfqrVYLwzAUnU6HdrvNdDr98EwmE0Vd12imaTIej5VhNBoxGAwYDofYtk2e5xwOB9I0VavM5RCKolDIIe3358FI/Xg8nqcsk3fKskTWJP8T2t/E97/1L/wBmYamwDz/NGYAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"2C5911B6 3009 4F89 B354 830BD67F2546\",\n    \"title\": \"2C5911B6 3009 4F89 B354 830BD67F2546\",\n    \"src\": \"/static/6172c602bcfd6615d9395f8145ec28c9/7d769/2C5911B6-3009-4F89-B354-830BD67F2546.png\",\n    \"srcSet\": [\"/static/6172c602bcfd6615d9395f8145ec28c9/5243c/2C5911B6-3009-4F89-B354-830BD67F2546.png 240w\", \"/static/6172c602bcfd6615d9395f8145ec28c9/ab158/2C5911B6-3009-4F89-B354-830BD67F2546.png 480w\", \"/static/6172c602bcfd6615d9395f8145ec28c9/7d769/2C5911B6-3009-4F89-B354-830BD67F2546.png 960w\", \"/static/6172c602bcfd6615d9395f8145ec28c9/06dba/2C5911B6-3009-4F89-B354-830BD67F2546.png 1016w\"],\n    \"sizes\": \"(max-width: 960px) 100vw, 960px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Convolution Module Structure:\"), \" starts with a gated convolution network mechanism with a pointwise convolution, a gated linear unit (GLU). Batchnorm is utilised to aid training deep models\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"960px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"16.249999999999996%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAArklEQVQI10WOy26CQBhGef/XMtZF1YUR6yVpUS5TAYGxMMzMrxwDieniLL7L4gQAIoJ3Fu8d3vUTzrkJ72VCxs3b//7982O2PERgGAiGAYwx6N8lXbnhuptRHBcopcjznPBzz259olEr/vI1cZyQqYzi8EFxmPOVhoTJFlXekceT4G3YVt8YfaEvI2x1oa5rtNYkPxlppGjriK6Jpr7RDf3tjKvOZFVKUsYYK6MgL+gZ45dRYSQjAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"EAE64A16 A20D 427C B6A1 28CEBFA3A038\",\n    \"title\": \"EAE64A16 A20D 427C B6A1 28CEBFA3A038\",\n    \"src\": \"/static/0fb0581caa701e72deffd601ed4cb5c0/7d769/EAE64A16-A20D-427C-B6A1-28CEBFA3A038.png\",\n    \"srcSet\": [\"/static/0fb0581caa701e72deffd601ed4cb5c0/5243c/EAE64A16-A20D-427C-B6A1-28CEBFA3A038.png 240w\", \"/static/0fb0581caa701e72deffd601ed4cb5c0/ab158/EAE64A16-A20D-427C-B6A1-28CEBFA3A038.png 480w\", \"/static/0fb0581caa701e72deffd601ed4cb5c0/7d769/EAE64A16-A20D-427C-B6A1-28CEBFA3A038.png 960w\", \"/static/0fb0581caa701e72deffd601ed4cb5c0/87339/EAE64A16-A20D-427C-B6A1-28CEBFA3A038.png 1440w\", \"/static/0fb0581caa701e72deffd601ed4cb5c0/a14b6/EAE64A16-A20D-427C-B6A1-28CEBFA3A038.png 1524w\"],\n    \"sizes\": \"(max-width: 960px) 100vw, 960px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Feed forward module:\"), \"\\nThe first Linear Layer expand the dimension by 4 and the second linear layer projects it back to the model dimension.\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"960px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"22.499999999999996%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA50lEQVQY062Qy0rDUABE8/8f4cYPcGMRoeDeR1I0tdVFkzSPapob82hyX0mPkEDxAxw4DAyzmXH4ZznjOKKURuk/KHVxKeWE1vrC3Js7l1xprNE42lgqESPFK93PJ325RyYrVL6lqSuEEDR1Q1ambNI1sYhRIqCPXbQI2Bd73lOfr+pAXlQ4wwDfic/h44Zj9ECbrNgurzmul2RJhOt6hGGEH71x97LACz3a8An//oomeMTduSyeb9nEPrusxZmXG846h6GGocfWKWcpMMZwOp3m6VZS9gWd6UA32DqZvLPdlEvbTx/+AvBCfJiwQjMSAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"1E3B98EE FD87 4E0B A880 58D64A174692\",\n    \"title\": \"1E3B98EE FD87 4E0B A880 58D64A174692\",\n    \"src\": \"/static/c865a738d5927affeb9b7a389ab61d03/7d769/1E3B98EE-FD87-4E0B-A880-58D64A174692.png\",\n    \"srcSet\": [\"/static/c865a738d5927affeb9b7a389ab61d03/5243c/1E3B98EE-FD87-4E0B-A880-58D64A174692.png 240w\", \"/static/c865a738d5927affeb9b7a389ab61d03/ab158/1E3B98EE-FD87-4E0B-A880-58D64A174692.png 480w\", \"/static/c865a738d5927affeb9b7a389ab61d03/7d769/1E3B98EE-FD87-4E0B-A880-58D64A174692.png 960w\", \"/static/c865a738d5927affeb9b7a389ab61d03/88569/1E3B98EE-FD87-4E0B-A880-58D64A174692.png 1108w\"],\n    \"sizes\": \"(max-width: 960px) 100vw, 960px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(\"p\", null, \"Three models have been defined, small, medium and large with 10M, 30M and 118M params, respectively by changing different combinations of network depth, model dimensions, number of attention heads \\u2026\"), mdx(\"h2\", null, \"Results on LibriSpeech:\"), mdx(\"p\", null, \"The model show improvements consistently over various model parameters size. \"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"960px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"70%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAAByklEQVQ4y3WT2aoCQQxE+/9/S1HxQR0VN0TH3XHfdy05gchw4RY09KS7K1VJJkynU/V6Pe12Ox2PR51OJ63Xa/X7fQ2HQ81mMy2XS8VxrMFgoPF4rCRJdD6f7ZwYa7Va6fP5KHCZS4/HwwLgcrnYpdFoZIkgz+VyajabKhQKajQaOhwOtq/X66pUKqrVano+nwqu8H6/GxGZ2b/fb71eL1uLxcLU4ADFrO12a+82m405Yn+9XhVQVy6XTeVkMjHLwMkg/g+o5w7K9vu9xQJ2Wq2WZaUODkrg5Ciez+e2xyqKADHusYhZDbFDvQhwIU3CYyd3Emyz0go591jAdzabVRRF6nQ6VhtvDA0D1JWkrsrV0nnIuOuxQLEzmYwdpoFCFABqBKknQgTADTVOnweCqKP1jIWr4iETAG6326++lMEbwF0sc+7vAg9LpZLy+byKxaKRkxXr3W73p8QtQ0zdAQJQm05ucwghA8r4MMzUBRVYJjuEJKAM3hTizCBWIUQ5QgIZIWTSq9Wqkf1tCip8DzFEgF8QEs4Zu59l1EGKRf/9fPoBaplXgCN+ANBut00pir081hQy0XZI3BJ2/RtClLl136MUqz7sNOgLeF8mN2q7xWUAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"03C0CF6A E78F 4D23 B3C8 8A8F3986C1C3\",\n    \"title\": \"03C0CF6A E78F 4D23 B3C8 8A8F3986C1C3\",\n    \"src\": \"/static/2e87f6295f0a3319e14ca68b1babf652/7d769/03C0CF6A-E78F-4D23-B3C8-8A8F3986C1C3.png\",\n    \"srcSet\": [\"/static/2e87f6295f0a3319e14ca68b1babf652/5243c/03C0CF6A-E78F-4D23-B3C8-8A8F3986C1C3.png 240w\", \"/static/2e87f6295f0a3319e14ca68b1babf652/ab158/03C0CF6A-E78F-4D23-B3C8-8A8F3986C1C3.png 480w\", \"/static/2e87f6295f0a3319e14ca68b1babf652/7d769/03C0CF6A-E78F-4D23-B3C8-8A8F3986C1C3.png 960w\", \"/static/2e87f6295f0a3319e14ca68b1babf652/e60c6/03C0CF6A-E78F-4D23-B3C8-8A8F3986C1C3.png 978w\"],\n    \"sizes\": \"(max-width: 960px) 100vw, 960px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n    \")), mdx(\"h2\", null, \"Reference\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2005.08100\"\n  }, mdx(\"em\", {\n    parentName: \"a\"\n  }, \"Conformer: Convolution-augmented Transformer for Speech Recognition\"))));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"In this papers, authors introduced Conformer, an architecture that  integrate components from CNN and Transformer  for end-to-end speech…","timeToRead":1,"banner":null}},"pageContext":{"slug":"/conformer-convolution-augmented-transformer-for-speech-recognition","formatString":"DD.MM.YYYY"}},
    "staticQueryHashes": ["2744905544","3090400250","318001574"]}