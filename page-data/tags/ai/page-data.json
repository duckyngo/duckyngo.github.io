{
    "componentChunkName": "component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-tag-query-tsx",
    "path": "/tags/ai",
    "result": {"data":{"allPost":{"nodes":[{"slug":"/integrating-stt-into-existing-call-centers-passively","title":"Technical Notes: Seamlessly Integrating STT into Legacy Call Center Systems via Passive Monitoring","date":"10.03.2025","excerpt":"Overview Deploying Speech-to-Text (STT) into legacy call center environments—especially those built on CTI platforms, Asterisk, or custom…","timeToRead":2,"description":null,"tags":[{"name":"AI","slug":"ai"},{"name":"STT","slug":"stt"},{"name":"VoIP","slug":"vo-ip"},{"name":"Call Center","slug":"call-center"},{"name":"Networking","slug":"networking"}]},{"slug":"/debugging-sip-connections-with-sngrep-on-linux","title":"Technical Notes: Debugging SIP Connections with sngrep on Linux","date":"01.03.2025","excerpt":"Overview When leading the implementation and maintenance of SIP-based communication systems—such as Asterisk, LiveKit SIP Gateway, or…","timeToRead":2,"description":null,"tags":[{"name":"AI","slug":"ai"},{"name":"VoIP","slug":"vo-ip"},{"name":"Linux","slug":"linux"},{"name":"Networking","slug":"networking"}]},{"slug":"/advanced-gpu-metrics-using-dcgm-exporter","title":"Techinal Notes: Monitoring Advanced GPU Metrics Using DCGM Exporter","date":"10.10.2024","excerpt":"Overview When working with GPU-intensive applications like machine learning, it's critical to monitor GPU metrics to ensure performance and…","timeToRead":2,"description":null,"tags":[{"name":"AI","slug":"ai"},{"name":"MLOps","slug":"ml-ops"}]},{"slug":"/setting-up-ubuntu-server-docker-compose","title":"Technical Notes: Setting Up an Ubuntu Server for Docker Compose","date":"02.08.2024","excerpt":"In this technical notes, I'll walk through the process of setting up an Ubuntu server to host Docker Compose services. This setup includes…","timeToRead":1,"description":null,"tags":[{"name":"AI","slug":"ai"},{"name":"MLOps","slug":"ml-ops"},{"name":"Linux","slug":"linux"}]},{"slug":"/prometheus-grafana-for-monitoring-mlops","title":"Technical Notes: Setting Up Prometheus + Grafana for Monitoring ML Systems","date":"29.07.2024","excerpt":"Recently, we deployed a microservice system for a Machine Learning application to an on-premises server. During the early stages of…","timeToRead":1,"description":null,"tags":[{"name":"AI","slug":"ai"},{"name":"MLOps","slug":"ml-ops"}]},{"slug":"/nvidia-triton-inference-server","title":"Technical Notes: NVIDIA Triton Inference Server","date":"01.07.2024","excerpt":"Recently, I explored the NVIDIA Triton Inference Server, and it completely changed how I think about deploying and optimizing AI models at…","timeToRead":2,"description":null,"tags":[{"name":"AI","slug":"ai"},{"name":"MLOps","slug":"ml-ops"}]},{"slug":"/how-to-boost-gpu-performance-with-nvlink","title":"How to Boosting GPU Performance with NVLink","date":"01.06.2024","excerpt":"When training large machine learning models across multiple GPUs, the way your GPUs are connected can have a huge impact on your training…","timeToRead":1,"description":null,"tags":[{"name":"AI","slug":"ai"}]}]}},"pageContext":{"slug":"ai","name":"AI","formatString":"DD.MM.YYYY"}},
    "staticQueryHashes": ["2744905544","3090400250","318001574"]}